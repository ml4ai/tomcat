@inproceedings{
pyarelal2023the,
title={The To{MCAT} Dataset},
author={Adarsh Pyarelal and Eric Duong and Caleb Jones Shibu and Paulo Soares and Savannah Boyd and Payal Khosla and Valeria Pfeifer and Diheng Zhang and Eric S Andrews and Rick Champlin and Vincent Paul Raymond and Meghavarshini Krishnaswamy and Clayton Morrison and Emily Butler and Kobus Barnard},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
url={https://openreview.net/forum?id=ZJWQfgXQb6}
}

@InProceedings{Zhang.ea:2022c,
author="Zhang, Liang
and Lieffers, Justin
and Pyarelal, Adarsh",
editor="Gurney, Nikolos
and Sukthankar, Gita",
title="Using Features at Multiple Temporal and Spatial Resolutions to Predict Human Behavior in Real Time",
booktitle="Computational Theory of Mind for Human-Machine Teams",
year="2022",
publisher={Springer, Cham},
doi=https://doi.org/10.1007/978-3-031-21671-8_13,
volume=13775,
pages="205--219",
abstract="When performing complex tasks, humans naturally reason at multiple temporal and spatial resolutions simultaneously. We contend that for an artificially intelligent agent to effectively model human teammates, i.e., demonstrate computational theory of mind (ToM), it should do the same. In this paper, we present an approach for integrating high and low-resolution spatial and temporal information to predict human behavior in real time and evaluate it on data collected from human subjects performing simulated urban search and rescue (USAR) missions in a Minecraft-based environment. Our model composes neural networks for high and low-resolution feature extraction with a neural network for behavior prediction, with all three networks trained simultaneously. The high-resolution extractor encodes dynamically changing goals robustly by taking as input the Manhattan distance difference between the humans' Minecraft avatars and candidate goals in the environment for the latest few actions, computed from a high-resolution gridworld representation. In contrast, the low-resolution extractor encodes participants' historical behavior using a historical state matrix computed from a low-resolution graph representation. Through supervised learning, our model acquires a robust prior for human behavior prediction, and can effectively deal with long-term observations. Our experimental results demonstrate that our method significantly improves prediction accuracy compared to approaches that only use high-resolution information.",
isbn="978-3-031-21671-8"
}

@InProceedings{Pyarelal.ea:2022,
author="Pyarelal, Adarsh
and Banerjee, Aditya
and Barnard, Kobus",
editor="Gurney, Nikolos and Sukthankar, Gita",
title="Modular Procedural Generation forÂ Voxel Maps",
booktitle="Computational Theory of Mind for Human-Machine Teams",
year="2022",
publisher={Springer, Cham},
eventtitle="AAAI-FSS 2021",
volume=13775,
pages="85--101",
doi="https://doi.org/10.1007/978-3-031-21671-8_6",
abstract="Task environments developed in Minecraft are becoming increasingly popular for artificial intelligence (AI) research. However, most of these are currently constructed manually, thus failing to take advantage of procedural content generation (PCG), a capability unique to virtual task environments. In this paper, we present mcg, an open-source library to facilitate implementing PCG algorithms for voxel-based environments such as Minecraft. The library is designed with human-machine teaming research in mind, and thus takes a `top-down' approach to generation, simultaneously generating low and high level machine-readable representations that are suitable for empirical research. These can be consumed by downstream AI applications that consider human spatial cognition. The benefits of this approach include rapid, scalable, and efficient development of virtual environments, the ability to control the statistics of the environment at a semantic level, and the ability to generate novel environments in response to player actions in real time.",
isbn="978-3-031-21671-8"
}

@inproceedings{Soares.ea:2021,
   author = {Paulo Soares and Adarsh Pyarelal and Kobus Barnard},
   title = {Probabilistic Modeling of Human Teams to Infer False Beliefs},
   booktitle = {AAAI Fall Symposium on Computational Theory of Mind for Human-Machine Teams},
   month = {nov},
   year = {2021},
   url = "https://drive.google.com/file/d/1_ncab_ZXAagVyWVwvTuTmbLqRXnfNFcB/view"
}

@inproceedings{nitschke-etal-2022-rule,
    title = "Rule Based Event Extraction for Artificial Social Intelligence",
    author = "Nitschke, Remo  and
      Wang, Yuwei  and
      Chen, Chen  and
      Pyarelal, Adarsh  and
      Sharp, Rebecca",
    booktitle = "Proceedings of the First Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Conference on Computational Linguistics",
    url = "https://aclanthology.org/2022.pandl-1.9",
    pages = "71--84",
    abstract = "Natural language (as opposed to structured communication modes
        such as Morse code) is by far the most common mode of communication
        between humans, and can thus provide significant insight into both
        individual mental states and interpersonal dynamics. As part of
        DARPA{'}s Artificial Social Intelligence for Successful Teams (ASIST)
        program, we are developing an AI agent team member that constructs and
        maintains models of their human teammates and provides appropriate
        task-relevant advice to improve team processes and mission performance.
        One of the key components of this agent is a module that uses a
        rule-based approach to extract task-relevant events from natural
        language utterances in real time, and publish them for consumption by
        downstream components. In this case study, we evaluate the performance
        of our rule-based event extraction system on a recently conducted ASIST
        experiment consisting of a simulated urban search and rescue mission in
        Minecraft. We compare the performance of our approach with that of a
        zero-shot neural classifier, and find that our approach outperforms the
        classifier for all event types, even when the classifier is used in an
        oracle setting where it knows how many events should be extracted from
        each utterance.",
}

@eprint{Basavaraj.ea:2022,
  doi = {10.48550/ARXIV.2211.09001},
  url = {https://arxiv.org/abs/2211.09001},
  author = {Basavaraj, Chinmai and Pyarelal, Adarsh and Carter, Evan},
  title = {Multi-Timescale Modeling of Human Behavior},
  publisher = {arXiv},
  year = {2022},
  primaryClass = "cs.LG",
  eprinttype   = {arxiv},
  eprint       = {2211.09001},
  copyright = {Creative Commons Attribution Share Alike 4.0 International},
}

@misc{Zhang.ea:2022a,
  doi = {10.48550/ARXIV.2211.06733},
  author = {Zhang, Liang and Lieffers, Justin and Pyarelal, Adarsh},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Deep Reinforcement Learning with Vector Quantized Encoding},
  publisher = {arXiv},
  year = {2022},
  primaryClass = "cs.LG",
  eprinttype   = {arxiv},
  eprint       = {2211.06733},

}

@misc{Culnan.ea:2023,
  author = {John Culnan
      and Ayesha Qamar
      and Meghavarshini Krishnaswamy
      and Yuwei Wang
      and Chen Chen
      and Md Messal Monem Miah
      and Shahriar Hormozi
      and Jonathan Tong
      and Ruihong Huang
      and Adarsh Pyarelal
  },
  title = {MultiCAT: Multimodal Communication Annotations for Teams},
  year = {2023},
  note = "In preparation"
}

@inproceedings{
qamar2023who,
title={Who is Speaking? Speaker-Aware Multiparty Dialogue Act Classification},
author={Ayesha Qamar and Adarsh Pyarelal and Ruihong Huang},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=NPkkvrv2Vp}
}

@inproceedings{
miah2023hierarchical,
title={Hierarchical Fusion for Online Multimodal Dialog Act Classification},
author={Md Messal Monem Miah and Adarsh Pyarelal and Ruihong Huang},
booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
year={2023},
url={https://openreview.net/forum?id=XILoK6g4va}
}

@inproceedings{culnan-etal-2021-ire,
    title = "Me, myself, and ire: Effects of automatic transcription quality on emotion, sarcasm, and personality detection",
    author = "Culnan, John  and
      Park, Seongjin  and
      Krishnaswamy, Meghavarshini  and
      Sharp, Rebecca",
    editor = "De Clercq, Orphee  and
      Balahur, Alexandra  and
      Sedoc, Joao  and
      Barriere, Valentin  and
      Tafreshi, Shabnam  and
      Buechel, Sven  and
      Hoste, Veronique",
    booktitle = "Proceedings of the Eleventh Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.wassa-1.26",
    pages = "250--256",
    abstract = "In deployment, systems that use speech as input must make use of automated transcriptions. Yet, typically when these systems are evaluated, gold transcriptions are assumed. We explicitly examine the impact of transcription errors on the downstream performance of a multi-modal system on three related tasks from three datasets: emotion, sarcasm, and personality detection. We include three separate transcription tools and show that while all automated transcriptions propagate errors that substantially impact downstream performance, the open-source tools fair worse than the paid tool, though not always straightforwardly, and word error rates do not correlate well with downstream performance. We further find that the inclusion of audio features partially mitigates transcription errors, but that a naive usage of a multi-task setup does not.",
}

@inproceedings{Rieffer_Champlin_2023,
    series={AHFE},
   title={Team Plan Recognition: A Review of the State of the Art},
   ISSN={2771-0718},
   url={http://dx.doi.org/10.54941/ahfe1003557},
   DOI={10.54941/ahfe1003557},
   booktitle={AHFE International},
   publisher={AHFE International},
   author={Rieffer-Champlin, Loren},
   year={2023},
   collection={AHFE} }

@misc{study_1_preregistration_and_results,
 title={Experiment 1 Preregistration},
 url={osf.io/c926k},
 DOI={10.17605/OSF.IO/C926K},
 publisher={OSF},
 author={Pyarelal, Adarsh},
 year={2022},
 month={Sep}
}

@misc{study_2_preregistration,
 title={UAZ Study 2 Preregistration},
 url={osf.io/amcu5},
 DOI={10.17605/OSF.IO/AMCU5},
 publisher={OSF},
 author={Pyarelal, Adarsh},
 year={2023},
 month={Jan}
}

@misc{study_2_results,
 title={UAZ Study 2 Results},
 url={osf.io/r3kwy},
 DOI={10.17605/OSF.IO/R3KWY},
 publisher={OSF},
 author={Pyarelal, Adarsh},
 year={2022},
 month={Sep}
}

@misc{study_3_preregistration,
 title={ToMCAT (UAZ + TAMU) Study 3 Preregistration},
 url={osf.io/hsy32},
 DOI={10.17605/OSF.IO/HSY32},
 publisher={OSF},
 author={Pyarelal, Adarsh},
 year={2023},
 month={Jan}
}

@misc{study_3_results,
 title={UAZ Study 3 Results},
 url={osf.io/t2rjm},
 DOI={10.17605/OSF.IO/T2RJM},
 publisher={OSF},
 author={Pyarelal, Adarsh and Ashton, Salena T and Astier, Joseph and Champlin, Loren and Barnard, Kobus and Butler, Emily and Huang, Ruihong and Jeong, Cheonkam and Kim, Stephen and Morrison, Clayton and et al.},
 year={2023},
 month={Jan}
}
