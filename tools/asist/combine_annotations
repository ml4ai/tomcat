#!/usr/bin/env python

# Script to combine annotations of incident commander inquiries from the Fall
# 2020 ASIST experiment.
# Author: Adarsh Pyarelal (adarsh@arizona.edu)

import json
from pprint import pprint
import argparse
from glob import glob
import logging
from logging import debug, info, warning, error
import pandas as pd
from itertools import groupby, accumulate, takewhile
from dataclasses import dataclass


def first_true(iterable, default=False, pred=None):
    """Returns the first true value in the iterable.

    If no true value is found, returns *default*

    If *pred* is not None, returns the first item
    for which pred(item) is true.

    Copied from https://docs.python.org/3/library/itertools.html#itertools-recipes
    """
    # first_true([a,b,c], x) --> a or b or c or x
    # first_true([a,b], x, f) --> a if f(a) else b if f(b) else x
    return next(filter(pred, iterable), default)


@dataclass(frozen=True)
class MediaFile:
    """Class to represent an MP4 video file corresponding to a trial."""

    # Path to the media file
    path: str

    # Length (in seconds) of the media file
    length: float


@dataclass(frozen=True)
class Event(object):
    """Class to represent a BORIS event."""

    timestamp: float
    code: str
    comment: str


@dataclass
class Trial(object):
    """Class to represent a trial (i.e. a mission)"""

    media_file: MediaFile

    def __post_init__(self):
        self.trial_number = self.media_file.path.split("Trial-")[1].split("_")[
            0
        ]
        self.participant: str = self.media_file.path.split("Member-")[1].split(
            "_"
        )[0]
        self.events = []


class Observation(object):
    """Class to represent a BORIS observation."""

    def __init__(self, label, observation):
        self.label: str = label

        # In the list comprehension below, we ensure that the filepath must end
        # with ".mp4". This is to deal with cases in which 'video_list.txt' was
        # erroneously added as a media file.
        self.media_files = [
            MediaFile(filepath, observation["media_info"]["length"][filepath])
            for filepath in observation["file"]["1"]
            if filepath.endswith(".mp4")
        ]

        self.cumulative_times = list(
            accumulate([f.length for f in self.media_files])
        )

        self.trials = {
            media_file.path: Trial(media_file)
            for media_file in self.media_files
        }

        for event in observation["events"]:
            aggregate_timestamp = event[0]
            # Figure out which video the event belongs to.
            media_file_index = first_true(
                enumerate(self.cumulative_times),
                pred=lambda tup: tup[1] > aggregate_timestamp,
            )[0]

            if media_file_index != 0:
                timestamp = (
                    aggregate_timestamp
                    - self.cumulative_times[media_file_index - 1]
                )
            else:
                timestamp = aggregate_timestamp

            media_file = self.media_files[media_file_index]

            code = event[2]

            # We call the strip() method on the comment string to deal with the
            # cases in which there are newline characters accidentally entered
            # into the comment field.
            comment = event[4].strip()

            self.trials[media_file.path].events.append(
                Event(timestamp, code, comment)
            )


@dataclass
class BorisProject:
    """Class to represent a BORIS project."""

    filepath: str

    def __post_init__(self):
        with open(self.filepath) as f:
            project = json.load(f)
            self.observations = {
                Observation(label, obs)
                for label, obs in project["observations"].items()
                if len(obs["events"]) != 0
            }


class MergedDataset(object):
    """Class to represent a dataset constructed by combining multiple BORIS
    projects."""

    def __init__(self, input_dir):
        self.projects = [BorisProject(f) for f in glob(f"{input_dir}/*")]
        self.validate()

    def validate(self):
        """Validate the dataset:
        - Check whether each trial has the expected number of events. (TODO)
        - Check if any trial has been annotated multiple times. (TODO)
        """

        # Number of expected events per trial
        n_expected_events = 15

        debug("Running validation.")
        for project in self.projects:
            for observation in project.observations:
                for trial in observation.trials.values():
                    # We check to see if there are 15 events per trial
                    if len(trial.events) != n_expected_events:
                        info(
                            f"Trial {trial.trial_number} in observation "
                            f"{observation.label} (in file: {project.filepath}) "
                            f"has {len(trial.events)} events instead of the "
                            f"expected number ({n_expected_events}). "
                            "This could be for a number of reasons (e.g., the "
                            "trial ended early), and is not necessarily something "
                            "you need to worry about."
                        )

    def to_tsv(self, output_filepath):
        records = []
        for project in self.projects:
            for observation in project.observations:
                for trial in observation.trials.values():
                    for event in trial.events:
                        record = {
                            "trial": trial.trial_number,
                            "timestamp": event.timestamp,
                            "event_code": event.code,
                            "comment": event.comment,
                        }
                        records.append(record)

        df = pd.DataFrame(records)
        df.to_csv(output_filepath, sep="\t", index=False)


if __name__ == "__main__":
    # Set logging level
    logging.basicConfig(level=logging.INFO)

    # Parse command line arguments
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "input_dir",
        help="Directory containing the annotation files (i.e. BORIS project files in JSON format)",
    )

    parser.add_argument(
        "output_file",
        help="Output file",
    )

    args = parser.parse_args()

    # Construct MergedDataset object
    md = MergedDataset(args.input_dir)

    # Output to TSV
    md.to_tsv(args.output_file)
