#!/usr/bin/env python

# Script to combine annotations of incident commander inquiries from the Fall
# 2020 ASIST experiment.

import json
from pprint import pprint
import argparse
from glob import glob
import logging
from logging import debug, info, warning, error

# Set logging level
logging.basicConfig(level=logging.DEBUG)

parser = argparse.ArgumentParser()
parser.add_argument(
    "input_dir",
    help="Directory containing the annotation files (i.e. BORIS project files in JSON format)",
)

parser.add_argument(
    "output_file",
    help="Output file",
)

args = parser.parse_args()

# Summary statistics
stats = {
    "n_project_files": 0,
    "n_observations": 0,
    "n_video_files": 0,
}


class Event(object):
    def __init__(self, event):
        self.timestamp = event[0]
        self.participant = event[1]
        self.response = event[2]
        self.comment = event[4]

    def __hash__(self):
        return hash(
            (self.timestamp, self.participant, self.response, self.comment)
        )


class Observation(object):
    def __init__(self, label, observation):
        self.label = label
        self.media_files = observation["media_info"]["length"].keys()
        self.events = {Event(event) for event in observation["events"]}

    def __hash__(self):
        return hash(self.label)


class BorisProject(object):
    def __init__(self, filepath):
        debug(f"Processing file {filepath}")
        self.filepath = filepath

        with open(self.filepath) as f:
            project = json.load(f)
            self.observations = {
                Observation(label, obs)
                for label, obs in project["observations"].items()
            }

    def __hash__(self):
        return hash(self.filepath)


class MergedDataset(object):
    def __init__(self, input_dir):
        self.projects = {BorisProject(f) for f in glob(f"{input_dir}/*")}
        self.validate()

    def validate(self):
        debug("Running validation.")
        for project in self.projects:
            for observation in project.observations:
                if len(observation.events) != 15 * len(
                    observation.media_files
                ):
                    warning(
                        f"Observation {observation.label} (in file {project.filepath}) has "
                        f"{len(observation.events)} events for "
                        f"{len(observation.media_files)} media files (expected "
                        f"number of events: {15*len(observation.media_files)})."
                    )

    def print_summary_stats(self):
        logging.debug("Summary statistics")
        logging.debug("------------------")
        logging.debug(stats)

md = MergedDataset(args.input_dir)
