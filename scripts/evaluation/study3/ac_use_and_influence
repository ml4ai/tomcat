#!/usr/bin/env python

"""Script for ASIST Study 3 evaluation"""

import json
from glob import glob
import logging
from logging import info, debug
import argparse
from tqdm import tqdm
import pandas as pd
from datetime import datetime

logging.basicConfig(level=logging.WARN)


def run_evaluation(args):
    ac_use_counts = {}
    n_interventions = 0
    intervention_type_counts = {}
    output_file = open(args.output, "w")
    n_files_processed = 0
    for filepath in tqdm(glob(args.data_dir + "/*T00*UAZ*.metadata")):
        n_files_processed += 1
        info(f"Processing {filepath}")
        with open(filepath) as f:
            for line in f:
                message = json.loads(line)
                if (
                    "topic" in message
                    and message["topic"]
                    == "agent/intervention/ASI_UAZ_TA1_ToMCAT/chat"
                ):
                    n_interventions += 1
                    explanation = message["data"]["explanation"][
                        "info"
                    ].replace("This intervention was triggered", "")

                    intervention_type = ""

                    if "did not get an answer" in explanation:
                        intervention_type = "help_request_reply"
                        ACs_used = {
                            "uaz_dialog_agent",
                            "AC_IHMC_TA2_Player-Proximity",
                        }
                    elif "did not ask" in explanation:
                        if "critical victim" in explanation:
                            intervention_type = (
                                "help_request_for_critical_victim"
                            )
                            ACs_used = {
                                "uaz_dialog_agent",
                                "AC_CMU_TA1_PyGLFoVAgent",
                                "AC_IHMC_TA2_Player-Proximity",
                            }
                        elif "threat room" in explanation:
                            intervention_type = "help_request_for_room_escape"
                            ACs_used = {
                                "uaz_dialog_agent",
                                "AC_CMU_TA1_PyGLFoVAgent",
                                "AC_IHMC_TA2_Player-Proximity",
                            }
                        else:
                            raise (
                                ValueError(
                                    "Could not determine help request "
                                    "intervention type for explanation "
                                    f"'{explanation}'"
                                )
                            )

                    elif "placed a marker" in explanation:
                        intervention_type = "marker_block"
                        ACs_used = {
                            "uaz_dialog_agent",
                            "AC_IHMC_TA2_Player-Proximity",
                        }
                    elif "ensure" in explanation:
                        intervention_type = "motivational"
                        ACs_used = {}
                    else:
                        raise (
                            ValueError(
                                "Could not determine intervention type: ",
                                explanation,
                            )
                        )
                    intervention_type_counts[intervention_type] = (
                        intervention_type_counts.get(intervention_type, 0) + 1
                    )
                    debug(intervention_type + "|" + explanation)
                    for ac in ACs_used:
                        ac_use_counts[ac] = ac_use_counts.get(ac, 0) + 1

    def write(line):
        output_file.write(line + "\n")

    write(f"Study 3 evaluation report (generated {datetime.utcnow().isoformat()+'Z'})")
    write("=================================================================")
    write("")
    write(f"Total number of files processed: {n_files_processed}")
    write("")
    write(f"Total number of interventions: {n_interventions}")
    write("")
    write("Intervention types")
    write("------------------")
    write(pd.Series(intervention_type_counts, name="Count").to_markdown())
    write("")
    write("AC Use Counts")
    write("-------------")
    write(
        pd.Series(
            ac_use_counts, name="Number of interventions participated in"
        ).to_markdown()
    )

    output_file.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description=__doc__,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--data_dir",
        help="Directory containing .metadata files",
        default="/media/mule/projects/tomcat/protected/study-3_2022",
    )
    parser.add_argument(
        "--output",
        help="Path to output report file",
        default="study_3_evaluation.md",
    )

    args = parser.parse_args()
    run_evaluation(args)
