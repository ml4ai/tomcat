from sampling.ancestral_sampling import AncestralSampling
from sampling.gibbs_sampling import GibbsSampling
import copy
import pandas as pd


class GibbsEstimator(GibbsSampling):

    def __init__(self, pgm):
        self.pgm = copy.deepcopy(pgm)

    def estimate_parameters(self, data, number_of_samples=500, burn_in_periods=100):
        if data.empty:
            raise TypeError('Data is mandatory for parameter estimation')

        samples = []

        # The following procedure will complete the data with samples for
        # the latent variables using ancestral sampling
        data_and_samples = self.get_initial_estimates(data)

        # Parameter nodes are constant which means their value are the same in the samples
        # generated by the above procedure. We need to assign their initial values to their
        # respective nodes in the graph so other nodes that have distribution depending on
        # these parameters can get their current sampled value from there
        sample = data_and_samples.iloc[0]
        sample = sample[
            self.pgm.get_parameter_nodes_id()]  # Sample contains only values assigned to the parameter nodes
        self.assign_values_to_nodes(sample)

        # Nodes we have to iterate over in the gibbs sampling, that is, the ones not observed in data
        latent_nodes = [node for node in self.pgm.get_nodes() if node.get_id() not in data.columns]

        number_of_data_points = len(data.index)

        for i in range(number_of_samples + burn_in_periods):
            for latent_node in latent_nodes:
                if latent_node.metadata.constant:
                    # Constant nodes are out of the nodes in the data plate. They only have one sample
                    # per all data points
                    posterior = self.get_posterior(latent_node, data_and_samples)
                    sampled_value = posterior.sample()
                    assignment = pd.Series({0: sampled_value}).repeat(number_of_data_points).reset_index(drop=True)

                    if latent_node.metadata.parameter:
                        sample[latent_node.get_id()] = sampled_value
                        latent_node.assignment = sampled_value
                else:
                    assignments = []
                    for _, data_point in data_and_samples.iterrows():
                        posterior = self.get_posterior(latent_node, pd.DataFrame(data_point).transpose())
                        assignments.append(posterior.sample())
                    assignment = pd.Series(assignments)

                # Update the columns of the sampled values for this latent node with the samples
                # we got for each data point
                data_and_samples[latent_node.get_id()] = assignment

            if i >= burn_in_periods:
                print('Sample {}'.format(i - burn_in_periods + 1))
                samples.append(sample)
            else:
                print('Burn-in Sample {}'.format(i + 1))

        return pd.DataFrame(samples)

    def get_initial_estimates(self, data):
        """
        This function completes the data with sampled values for each latent variable in each data point.
        Constant nodes will preserve the value sampled in the first data point
        """
        sampling = AncestralSampling(self.pgm)
        samples = []

        copied_data = data.copy()
        number_of_data_points = len(data.index)

        # Constant nodes will have a constant value for all the sampled data
        sample = sampling.sample()
        for constant_node in self.pgm.get_constant_nodes():
            copied_data[constant_node.get_id()] = sample[constant_node.get_id()].repeat(
                number_of_data_points).reset_index(drop=True)

        for _, data_point_observations in copied_data.iterrows():
            sample = sampling.sample(observations=data_point_observations)
            samples.append(sample)

        return pd.concat(samples, ignore_index=True)
